{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15jbOJUKxeLr",
        "outputId": "9f1eb692-886a-4ce1-dc17-4e72056c4164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (3.3.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.7.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "from sklearn import preprocessing\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import string"
      ],
      "metadata": {
        "id": "4wSI5-8BxjEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.semi_supervised import LabelSpreading"
      ],
      "metadata": {
        "id": "jOBQuCoyxtqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "Fjt9qekCxvnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lyrics = pd.read_csv(\"rap_song_analyis.csv\")\n",
        "df_spotify = pd.read_csv(\"rap_oy_spotify.csv\")\n",
        "df_search = pd.read_csv(\"rap_oy_search_trends.csv\")\n",
        "df_bb = pd.read_csv(\"rap_oy_billboard_features.csv\")"
      ],
      "metadata": {
        "id": "y1MHZM5zxxTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Len of spotify data = \", len(df_spotify))\n",
        "print(\"Len of billboard data = \", len(df_bb))\n",
        "print(\"Len of lyrics data = \", len(df_lyrics))\n",
        "print(\"Len of search trends data = \", len(df_search))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0gC8jb20SUQ",
        "outputId": "f5c0028c-a3a6-43f3-d7b7-af0ccfe6dbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len of spotify data =  103\n",
            "Len of billboard data =  103\n",
            "Len of lyrics data =  103\n",
            "Len of search trends data =  97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "MOgCHZ1AIPUn",
        "outputId": "01a332b6-3133-4116-969a-5103366354b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  year    award category              song  \\\n",
              "0             0  2004  Song of the Year     Lose Yourself   \n",
              "1             1  2004  Song of the Year         Beautiful   \n",
              "2             2  2004  Song of the Year    Excuse Me Miss   \n",
              "3             3  2004  Song of the Year        In da Club   \n",
              "4             4  2004  Song of the Year           Work It   \n",
              "..          ...   ...               ...               ...   \n",
              "98           98  2023  Song of the Year   Churchill Downs   \n",
              "99           99  2023  Song of the Year           God Did   \n",
              "100         100  2023  Song of the Year  The Heart Part 5   \n",
              "101         101  2023  Song of the Year          Pushin P   \n",
              "102         102  2023  Song of the Year        Wait for U   \n",
              "\n",
              "                                    artist wasWinner  weeks_in_top_25  \\\n",
              "0                                   Eminem       yes               19   \n",
              "1                  Snoop Dogg and Pharrell        no               27   \n",
              "2                       Jay-Z and Pharrell        no               12   \n",
              "3                                  50 Cent        no               23   \n",
              "4                            Missy Elliott        no               20   \n",
              "..                                     ...       ...              ...   \n",
              "98             Jack Harlow featuring Drake        no                1   \n",
              "99           DJ Khaled featuring Rick Ross        no                1   \n",
              "100                         Kendrick Lamar        no                2   \n",
              "101  Gunna and Future featuring Young Thug        no               13   \n",
              "102        Future featuring Drake and Tems        no               21   \n",
              "\n",
              "     weeks_in_top_10  weeks_on_chart  peak_position  average_position  \n",
              "0                 16              23              1             10.57  \n",
              "1                 16              31              2             13.48  \n",
              "2                  3              19              8             34.00  \n",
              "3                 17              30              1             15.10  \n",
              "4                 16              22              2              8.77  \n",
              "..               ...             ...            ...               ...  \n",
              "98                 0               2             23             50.50  \n",
              "99                 0               3             17             47.67  \n",
              "100                0               4             15             46.00  \n",
              "101                5              20              7             32.35  \n",
              "102               20              21              1              5.57  \n",
              "\n",
              "[103 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22829668-124a-4826-81c1-eb6b661dd422\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>year</th>\n",
              "      <th>award category</th>\n",
              "      <th>song</th>\n",
              "      <th>artist</th>\n",
              "      <th>wasWinner</th>\n",
              "      <th>weeks_in_top_25</th>\n",
              "      <th>weeks_in_top_10</th>\n",
              "      <th>weeks_on_chart</th>\n",
              "      <th>peak_position</th>\n",
              "      <th>average_position</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2004</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Lose Yourself</td>\n",
              "      <td>Eminem</td>\n",
              "      <td>yes</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>10.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2004</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Beautiful</td>\n",
              "      <td>Snoop Dogg and Pharrell</td>\n",
              "      <td>no</td>\n",
              "      <td>27</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>13.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Excuse Me Miss</td>\n",
              "      <td>Jay-Z and Pharrell</td>\n",
              "      <td>no</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>34.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2004</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>In da Club</td>\n",
              "      <td>50 Cent</td>\n",
              "      <td>no</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>15.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2004</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Work It</td>\n",
              "      <td>Missy Elliott</td>\n",
              "      <td>no</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>8.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>2023</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Churchill Downs</td>\n",
              "      <td>Jack Harlow featuring Drake</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>50.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>2023</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>God Did</td>\n",
              "      <td>DJ Khaled featuring Rick Ross</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>47.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>100</td>\n",
              "      <td>2023</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>The Heart Part 5</td>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>46.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>2023</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Pushin P</td>\n",
              "      <td>Gunna and Future featuring Young Thug</td>\n",
              "      <td>no</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>32.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>2023</td>\n",
              "      <td>Song of the Year</td>\n",
              "      <td>Wait for U</td>\n",
              "      <td>Future featuring Drake and Tems</td>\n",
              "      <td>no</td>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>5.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22829668-124a-4826-81c1-eb6b661dd422')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22829668-124a-4826-81c1-eb6b661dd422 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22829668-124a-4826-81c1-eb6b661dd422');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = list(df_spotify[\"song\"])\n",
        "list2 = list(df_bb[\"song\"])\n",
        "list3 = list(df_lyrics[\"song\"])\n",
        "list4 = list(df_search[\"song\"])"
      ],
      "metadata": {
        "id": "2WjV5BvW0VGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list11 = list(df_spotify[\"artist\"])\n",
        "# list22 = list(df_bb[\"artist\"])\n",
        "# list33 = list(df_lyrics[\"artist\"])\n",
        "# list44 = list(df_search[\"artist\"])\n",
        "\n",
        "# list11 = [s.lstrip() for s in list11]\n",
        "# list22 = [s.lstrip() for s in list22]\n",
        "# list33 = [s.lstrip() for s in list33]\n",
        "# list44 = [s.lstrip() for s in list44]\n",
        "\n",
        "# list11 = [s.split()[0] for s in list11]\n",
        "# list22 = [s.split()[0] for s in list22]\n",
        "# list33 = [s.split()[0] for s in list33]\n",
        "# list44 = [s.split()[0] for s in list44]\n",
        "\n",
        "# key1 = [list1[i] + list11[i] for i in range(len(list1))]\n",
        "# key2 = [list2[i] + list22[i] for i in range(len(list2))]\n",
        "# key3 = [list3[i] + list33[i] for i in range(len(list3))]\n",
        "# key4 = [list4[i] + list44[i] for i in range(len(list4))]\n",
        "\n",
        "key1 = [list1[i] for i in range(len(list1))]\n",
        "key2 = [list2[i] for i in range(len(list2))]\n",
        "key3 = [list3[i] for i in range(len(list3))]\n",
        "key4 = [list4[i] for i in range(len(list4))]\n",
        "\n",
        "key1 = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in key1]\n",
        "key2 = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in key2]\n",
        "key3 = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in key3]\n",
        "key4 = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in key4]"
      ],
      "metadata": {
        "id": "M7svhibT1ONC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spotify[\"song_key\"] = key1\n",
        "df_bb[\"song_key\"] = key2\n",
        "df_lyrics[\"song_key\"] = key3\n",
        "df_search[\"song_key\"] = key4"
      ],
      "metadata": {
        "id": "Gk0Q66jB0ySE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the dataframes on the common column 'song_key'\n",
        "merged_df = pd.merge(df_bb, df_spotify, on='song_key', how='inner')\n",
        "merged_df = pd.merge(merged_df, df_lyrics, on='song_key', how='inner')\n",
        "# merged_df = pd.merge(merged_df,df_search, on='song_key', how='inner')\n",
        "\n",
        "# Only keep rows that have information from all 3 dataframes\n",
        "result_df = merged_df.dropna()"
      ],
      "metadata": {
        "id": "aEoQCfjX0y40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = result_df[['year_x', 'song_x', 'artist_x',\n",
        "       'wasWinner_x', 'weeks_in_top_25', 'weeks_in_top_10', 'weeks_on_chart',\n",
        "       'peak_position', 'average_position', 'danceability',\n",
        "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
        "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
        "       'time_signature', 'num_words', 'vocab_diveristy',\n",
        "       'pos_sen', 'neg_sen', 'happy', 'fear', 'anger', 'sad', 'surprise',\n",
        "       'profanity']]"
      ],
      "metadata": {
        "id": "sMnHImek5_kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows based on all columns\n",
        "result_df = result_df.reset_index(drop=True).drop_duplicates()"
      ],
      "metadata": {
        "id": "JgOtPPnBPuXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Len of combined data = \", len(result_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DwaVjScPyIH",
        "outputId": "a973b378-a04c-4617-a275-cf90a717b7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len of combined data =  101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows based on all columns\n",
        "result_df = result_df.reset_index(drop=True).drop_duplicates(subset=['weeks_in_top_25', 'weeks_in_top_10', 'weeks_on_chart',\n",
        "       'peak_position', 'average_position', 'danceability',\n",
        "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
        "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
        "       'time_signature', 'num_words', 'vocab_diveristy',\n",
        "       'pos_sen', 'neg_sen', 'happy', 'fear', 'anger', 'sad', 'surprise',\n",
        "       'profanity'])"
      ],
      "metadata": {
        "id": "ZIEr-QyHP0L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsK1rVz1P3ZE",
        "outputId": "fec8148a-e82a-4b9d-c155-444e1c45ce3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['year_x', 'song_x', 'artist_x', 'wasWinner_x', 'weeks_in_top_25',\n",
              "       'weeks_in_top_10', 'weeks_on_chart', 'peak_position',\n",
              "       'average_position', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
              "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
              "       'valence', 'tempo', 'duration_ms', 'time_signature', 'num_words',\n",
              "       'vocab_diveristy', 'pos_sen', 'neg_sen', 'happy', 'fear', 'anger',\n",
              "       'sad', 'surprise', 'profanity', 'class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv(\"rap_combined_not_full.csv\")"
      ],
      "metadata": {
        "id": "kEEDzVuOP_Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into features and target\n",
        "\n",
        "feature_list = ['weeks_in_top_25', 'weeks_in_top_10', 'weeks_on_chart',\n",
        "       'peak_position', 'average_position', 'danceability',\n",
        "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
        "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
        "       'time_signature', 'num_words', 'vocab_diveristy',\n",
        "       'pos_sen', 'neg_sen', 'happy', 'fear', 'anger', 'sad', 'surprise',\n",
        "       'profanity']\n",
        "\n",
        "result_df['class'] = result_df['wasWinner_x'].replace({'yes': 1, 'no': 0})"
      ],
      "metadata": {
        "id": "j9fX_WOMP6Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(result_df.corr())\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "NUbFU_sFQEp4",
        "outputId": "2656f025-46bc-45df-ef5d-55611e4fb999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(result_df.corr().unstack().sort_values().drop_duplicates())[0:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dLA11MkiKne",
        "outputId": "0cfdd858-5bec-4872-e244-58b60534c7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "weeks_in_top_25   average_position   -0.65\n",
              "average_position  weeks_on_chart     -0.63\n",
              "weeks_on_chart    peak_position      -0.61\n",
              "weeks_in_top_10   average_position   -0.56\n",
              "weeks_in_top_25   peak_position      -0.55\n",
              "peak_position     weeks_in_top_10    -0.46\n",
              "time_signature    duration_ms        -0.42\n",
              "duration_ms       danceability       -0.41\n",
              "                  valence            -0.41\n",
              "liveness          duration_ms        -0.41\n",
              "speechiness       duration_ms        -0.41\n",
              "duration_ms       acousticness       -0.41\n",
              "                  instrumentalness   -0.41\n",
              "energy            duration_ms        -0.41\n",
              "duration_ms       mode               -0.41\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(result_df.corr().unstack().sort_values().drop_duplicates())[-60:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMYW_LpOi4Ob",
        "outputId": "24e1d97a-a8c7-4df6-a1c1-aa90be052c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "weeks_on_chart    weeks_in_top_10    0.70\n",
              "                  weeks_in_top_25    0.87\n",
              "weeks_in_top_25   weeks_in_top_10    0.87\n",
              "key               loudness           0.92\n",
              "mode              key                0.93\n",
              "key               instrumentalness   0.94\n",
              "speechiness       key                0.94\n",
              "danceability      key                0.94\n",
              "liveness          key                0.94\n",
              "time_signature    key                0.94\n",
              "energy            key                0.94\n",
              "valence           key                0.94\n",
              "acousticness      key                0.94\n",
              "average_position  peak_position      0.96\n",
              "loudness          time_signature     0.98\n",
              "mode              loudness           0.98\n",
              "danceability      loudness           0.98\n",
              "loudness          instrumentalness   0.98\n",
              "                  liveness           0.98\n",
              "                  valence            0.98\n",
              "speechiness       loudness           0.98\n",
              "loudness          acousticness       0.98\n",
              "energy            loudness           0.98\n",
              "time_signature    mode               1.00\n",
              "acousticness      mode               1.00\n",
              "mode              valence            1.00\n",
              "danceability      mode               1.00\n",
              "mode              liveness           1.00\n",
              "time_signature    acousticness       1.00\n",
              "instrumentalness  time_signature     1.00\n",
              "time_signature    liveness           1.00\n",
              "                  danceability       1.00\n",
              "speechiness       time_signature     1.00\n",
              "mode              energy             1.00\n",
              "energy            time_signature     1.00\n",
              "mode              speechiness        1.00\n",
              "time_signature    valence            1.00\n",
              "instrumentalness  mode               1.00\n",
              "liveness          valence            1.00\n",
              "acousticness      liveness           1.00\n",
              "                  danceability       1.00\n",
              "danceability      liveness           1.00\n",
              "acousticness      valence            1.00\n",
              "danceability      energy             1.00\n",
              "energy            acousticness       1.00\n",
              "                  liveness           1.00\n",
              "instrumentalness  valence            1.00\n",
              "speechiness       valence            1.00\n",
              "acousticness      instrumentalness   1.00\n",
              "instrumentalness  liveness           1.00\n",
              "danceability      speechiness        1.00\n",
              "valence           energy             1.00\n",
              "acousticness      speechiness        1.00\n",
              "valence           danceability       1.00\n",
              "speechiness       liveness           1.00\n",
              "instrumentalness  danceability       1.00\n",
              "                  energy             1.00\n",
              "speechiness       instrumentalness   1.00\n",
              "energy            speechiness        1.00\n",
              "year_x            year_x             1.00\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PEwDXnppjJVi",
        "outputId": "84c84126-a258-4082-ba7f-f714e047e33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  year_x  weeks_in_top_25  weeks_in_top_10  weeks_on_chart  \\\n",
              "year_x              1.00            -0.17            -0.13           -0.22   \n",
              "weeks_in_top_25    -0.17             1.00             0.87            0.87   \n",
              "weeks_in_top_10    -0.13             0.87             1.00            0.70   \n",
              "weeks_on_chart     -0.22             0.87             0.70            1.00   \n",
              "peak_position       0.18            -0.55            -0.46           -0.61   \n",
              "average_position    0.20            -0.65            -0.56           -0.63   \n",
              "danceability        0.06            -0.09            -0.07           -0.13   \n",
              "energy              0.06            -0.10            -0.08           -0.14   \n",
              "key                 0.06            -0.07            -0.03           -0.08   \n",
              "loudness            0.04            -0.09            -0.07           -0.12   \n",
              "mode                0.06            -0.10            -0.07           -0.14   \n",
              "speechiness         0.06            -0.10            -0.08           -0.14   \n",
              "acousticness        0.06            -0.10            -0.08           -0.14   \n",
              "instrumentalness    0.06            -0.10            -0.08           -0.14   \n",
              "liveness            0.06            -0.10            -0.07           -0.13   \n",
              "valence             0.06            -0.09            -0.07           -0.13   \n",
              "tempo               0.01             0.17             0.06            0.18   \n",
              "duration_ms        -0.05            -0.11            -0.09           -0.12   \n",
              "time_signature      0.05            -0.09            -0.07           -0.13   \n",
              "num_words          -0.01            -0.01            -0.03           -0.01   \n",
              "vocab_diveristy     0.14            -0.18            -0.21           -0.19   \n",
              "pos_sen             0.08             0.04             0.06           -0.06   \n",
              "neg_sen             0.15            -0.10            -0.10           -0.06   \n",
              "happy               0.10             0.16             0.10            0.14   \n",
              "fear               -0.03             0.01            -0.06            0.09   \n",
              "anger               0.02            -0.08            -0.02           -0.09   \n",
              "sad                -0.11            -0.04             0.05           -0.03   \n",
              "surprise            0.02            -0.06            -0.07           -0.13   \n",
              "profanity           0.15             0.00            -0.01            0.02   \n",
              "class              -0.00             0.14             0.14            0.12   \n",
              "\n",
              "                  peak_position  average_position  danceability  energy   key  \\\n",
              "year_x                     0.18              0.20          0.06    0.06  0.06   \n",
              "weeks_in_top_25           -0.55             -0.65         -0.09   -0.10 -0.07   \n",
              "weeks_in_top_10           -0.46             -0.56         -0.07   -0.08 -0.03   \n",
              "weeks_on_chart            -0.61             -0.63         -0.13   -0.14 -0.08   \n",
              "peak_position              1.00              0.96          0.25    0.25  0.22   \n",
              "average_position           0.96              1.00          0.23    0.23  0.21   \n",
              "danceability               0.25              0.23          1.00    1.00  0.94   \n",
              "energy                     0.25              0.23          1.00    1.00  0.94   \n",
              "key                        0.22              0.21          0.94    0.94  1.00   \n",
              "loudness                   0.21              0.20          0.98    0.98  0.92   \n",
              "mode                       0.25              0.23          1.00    1.00  0.93   \n",
              "speechiness                0.25              0.23          1.00    1.00  0.94   \n",
              "acousticness               0.25              0.23          1.00    1.00  0.94   \n",
              "instrumentalness           0.25              0.23          1.00    1.00  0.94   \n",
              "liveness                   0.25              0.23          1.00    1.00  0.94   \n",
              "valence                    0.25              0.23          1.00    1.00  0.94   \n",
              "tempo                     -0.08             -0.10         -0.02   -0.02 -0.02   \n",
              "duration_ms               -0.22             -0.18         -0.41   -0.41 -0.39   \n",
              "time_signature             0.25              0.23          1.00    1.00  0.94   \n",
              "num_words                 -0.20             -0.21         -0.06   -0.06 -0.07   \n",
              "vocab_diveristy            0.17              0.19         -0.06   -0.06 -0.05   \n",
              "pos_sen                   -0.10             -0.11          0.06    0.06  0.06   \n",
              "neg_sen                   -0.02              0.02         -0.15   -0.15 -0.14   \n",
              "happy                     -0.02             -0.02         -0.06   -0.06 -0.03   \n",
              "fear                      -0.07             -0.06          0.23    0.23  0.18   \n",
              "anger                      0.06              0.07         -0.09   -0.09 -0.04   \n",
              "sad                       -0.12             -0.13         -0.13   -0.13 -0.09   \n",
              "surprise                   0.15              0.14         -0.01   -0.00 -0.04   \n",
              "profanity                 -0.07             -0.07         -0.05   -0.05 -0.02   \n",
              "class                     -0.06             -0.07         -0.05   -0.05 -0.12   \n",
              "\n",
              "                  loudness  ...  vocab_diveristy  pos_sen  neg_sen  happy  \\\n",
              "year_x                0.04  ...             0.14     0.08     0.15   0.10   \n",
              "weeks_in_top_25      -0.09  ...            -0.18     0.04    -0.10   0.16   \n",
              "weeks_in_top_10      -0.07  ...            -0.21     0.06    -0.10   0.10   \n",
              "weeks_on_chart       -0.12  ...            -0.19    -0.06    -0.06   0.14   \n",
              "peak_position         0.21  ...             0.17    -0.10    -0.02  -0.02   \n",
              "average_position      0.20  ...             0.19    -0.11     0.02  -0.02   \n",
              "danceability          0.98  ...            -0.06     0.06    -0.15  -0.06   \n",
              "energy                0.98  ...            -0.06     0.06    -0.15  -0.06   \n",
              "key                   0.92  ...            -0.05     0.06    -0.14  -0.03   \n",
              "loudness              1.00  ...            -0.04     0.02    -0.18  -0.10   \n",
              "mode                  0.98  ...            -0.06     0.06    -0.15  -0.06   \n",
              "speechiness           0.98  ...            -0.05     0.06    -0.15  -0.06   \n",
              "acousticness          0.98  ...            -0.05     0.06    -0.15  -0.06   \n",
              "instrumentalness      0.98  ...            -0.06     0.06    -0.15  -0.06   \n",
              "liveness              0.98  ...            -0.05     0.06    -0.15  -0.06   \n",
              "valence               0.98  ...            -0.06     0.06    -0.15  -0.06   \n",
              "tempo                -0.00  ...            -0.16    -0.13     0.05   0.16   \n",
              "duration_ms          -0.38  ...             0.02     0.09    -0.02  -0.02   \n",
              "time_signature        0.98  ...            -0.06     0.05    -0.15  -0.06   \n",
              "num_words            -0.05  ...            -0.20    -0.01     0.23  -0.26   \n",
              "vocab_diveristy      -0.04  ...             1.00    -0.07     0.08   0.01   \n",
              "pos_sen               0.02  ...            -0.07     1.00    -0.13   0.41   \n",
              "neg_sen              -0.18  ...             0.08    -0.13     1.00  -0.08   \n",
              "happy                -0.10  ...             0.01     0.41    -0.08   1.00   \n",
              "fear                  0.24  ...            -0.02    -0.02     0.11  -0.30   \n",
              "anger                -0.08  ...            -0.05    -0.13     0.25  -0.25   \n",
              "sad                  -0.14  ...            -0.01    -0.12    -0.13  -0.24   \n",
              "surprise              0.02  ...             0.07    -0.16    -0.10  -0.21   \n",
              "profanity            -0.03  ...             0.35    -0.24     0.42  -0.16   \n",
              "class                -0.05  ...             0.07     0.11    -0.05   0.04   \n",
              "\n",
              "                  fear  anger   sad  surprise  profanity  class  \n",
              "year_x           -0.03   0.02 -0.11      0.02       0.15  -0.00  \n",
              "weeks_in_top_25   0.01  -0.08 -0.04     -0.06       0.00   0.14  \n",
              "weeks_in_top_10  -0.06  -0.02  0.05     -0.07      -0.01   0.14  \n",
              "weeks_on_chart    0.09  -0.09 -0.03     -0.13       0.02   0.12  \n",
              "peak_position    -0.07   0.06 -0.12      0.15      -0.07  -0.06  \n",
              "average_position -0.06   0.07 -0.13      0.14      -0.07  -0.07  \n",
              "danceability      0.23  -0.09 -0.13     -0.01      -0.05  -0.05  \n",
              "energy            0.23  -0.09 -0.13     -0.00      -0.05  -0.05  \n",
              "key               0.18  -0.04 -0.09     -0.04      -0.02  -0.12  \n",
              "loudness          0.24  -0.08 -0.14      0.02      -0.03  -0.05  \n",
              "mode              0.23  -0.10 -0.12      0.00      -0.06  -0.04  \n",
              "speechiness       0.23  -0.09 -0.13     -0.01      -0.05  -0.05  \n",
              "acousticness      0.23  -0.09 -0.13     -0.00      -0.06  -0.05  \n",
              "instrumentalness  0.23  -0.09 -0.13     -0.00      -0.05  -0.05  \n",
              "liveness          0.23  -0.09 -0.13     -0.00      -0.05  -0.05  \n",
              "valence           0.23  -0.09 -0.13     -0.01      -0.06  -0.05  \n",
              "tempo             0.05  -0.06 -0.06     -0.10       0.03   0.02  \n",
              "duration_ms      -0.10   0.03  0.06      0.05       0.05   0.06  \n",
              "time_signature    0.23  -0.09 -0.12     -0.01      -0.06  -0.05  \n",
              "num_words         0.28  -0.03  0.00     -0.03       0.38   0.07  \n",
              "vocab_diveristy  -0.02  -0.05 -0.01      0.07       0.35   0.07  \n",
              "pos_sen          -0.02  -0.13 -0.12     -0.16      -0.24   0.11  \n",
              "neg_sen           0.11   0.25 -0.13     -0.10       0.42  -0.05  \n",
              "happy            -0.30  -0.25 -0.24     -0.21      -0.16   0.04  \n",
              "fear              1.00  -0.20 -0.26     -0.34       0.30  -0.01  \n",
              "anger            -0.20   1.00 -0.06     -0.22      -0.03  -0.12  \n",
              "sad              -0.26  -0.06  1.00     -0.36      -0.00   0.00  \n",
              "surprise         -0.34  -0.22 -0.36      1.00      -0.12   0.06  \n",
              "profanity         0.30  -0.03 -0.00     -0.12       1.00  -0.07  \n",
              "class            -0.01  -0.12  0.00      0.06      -0.07   1.00  \n",
              "\n",
              "[30 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de1382ac-ef1a-4e98-894b-5dc61df360d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year_x</th>\n",
              "      <th>weeks_in_top_25</th>\n",
              "      <th>weeks_in_top_10</th>\n",
              "      <th>weeks_on_chart</th>\n",
              "      <th>peak_position</th>\n",
              "      <th>average_position</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>...</th>\n",
              "      <th>vocab_diveristy</th>\n",
              "      <th>pos_sen</th>\n",
              "      <th>neg_sen</th>\n",
              "      <th>happy</th>\n",
              "      <th>fear</th>\n",
              "      <th>anger</th>\n",
              "      <th>sad</th>\n",
              "      <th>surprise</th>\n",
              "      <th>profanity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>year_x</th>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_in_top_25</th>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_in_top_10</th>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_on_chart</th>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>peak_position</th>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.21</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_position</th>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>danceability</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>key</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loudness</th>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mode</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speechiness</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acousticness</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instrumentalness</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>liveness</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence</th>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration_ms</th>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_signature</th>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_words</th>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.28</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vocab_diveristy</th>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos_sen</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neg_sen</th>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.42</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profanity</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.42</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de1382ac-ef1a-4e98-894b-5dc61df360d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de1382ac-ef1a-4e98-894b-5dc61df360d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de1382ac-ef1a-4e98-894b-5dc61df360d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_variance = {}\n",
        "for feature in feature_list:\n",
        "    values = np.array(result_df[feature])\n",
        "    x_norm = (values-np.min(values))/(np.max(values)-np.min(values))\n",
        "    var = np.var(x_norm)\n",
        "    #print(\"Variance for\", feature, \"=\", var)\n",
        "    feature_variance[feature] = var"
      ],
      "metadata": {
        "id": "Duk7vvGJQGz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_variance = sorted(feature_variance.items(), key=lambda x:x[1])\n",
        "features_sortedx = []\n",
        "for var in sorted_variance:\n",
        "  print(var)\n",
        "  features_sortedx.append(var[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9MEjoM6QLW3",
        "outputId": "8e272b5b-688e-4428-943c-6cdf127b863e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('loudness', 0.00846953856975993)\n",
            "('time_signature', 0.00939414049586777)\n",
            "('energy', 0.009796407988818858)\n",
            "('mode', 0.009811370830289745)\n",
            "('valence', 0.009821089490148814)\n",
            "('danceability', 0.009842259666214836)\n",
            "('speechiness', 0.009869134327241496)\n",
            "('liveness', 0.009870246852791455)\n",
            "('acousticness', 0.00987634020683224)\n",
            "('instrumentalness', 0.009897865162751573)\n",
            "('key', 0.010189919649379105)\n",
            "('duration_ms', 0.014009249942909873)\n",
            "('anger', 0.017585893491124258)\n",
            "('surprise', 0.02062677122769065)\n",
            "('vocab_diveristy', 0.026280208706098)\n",
            "('num_words', 0.029771441640162783)\n",
            "('neg_sen', 0.03453313042981252)\n",
            "('happy', 0.04206518333926664)\n",
            "('fear', 0.04695854545454546)\n",
            "('sad', 0.048330653894210734)\n",
            "('pos_sen', 0.04960195971634842)\n",
            "('tempo', 0.05404197015842072)\n",
            "('weeks_on_chart', 0.05800347222222222)\n",
            "('weeks_in_top_10', 0.08155310650887575)\n",
            "('average_position', 0.08954117705318801)\n",
            "('weeks_in_top_25', 0.09304794921874997)\n",
            "('peak_position', 0.10486790685104273)\n",
            "('profanity', 0.11381560085208607)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lazy_predict(result_df, feature_list, norm=False, print=False):\n",
        "  X = result_df[feature_list]\n",
        "  y = result_df[\"class\"]\n",
        "\n",
        "  if norm == True:\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X)\n",
        "    X = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.15,random_state=42)\n",
        "\n",
        "  clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "  models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "  if print == True:\n",
        "    print(models)\n",
        "  return models"
      ],
      "metadata": {
        "id": "d7ebY1fBQNpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "  models = lazy_predict(result_df, features_sortedx[i:], norm=True)\n",
        "  print(\"Removing\", i, \"features\", \"F1 Score is\", models.iloc[0][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHNkytFESCbi",
        "outputId": "911f0d95-fa3c-4b08-caf4-6f634268a8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 0 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 1 features F1 Score is 0.5045454545454545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 2 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 3 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 4 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 5 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 14.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 6 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 27.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 7 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 30.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 8 features F1 Score is 0.6475279106858054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 30.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 9 features F1 Score is 0.5291101055806938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 10 features F1 Score is 0.5888888888888888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 11 features F1 Score is 0.5888888888888888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 12 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 13 features F1 Score is 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 13.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 14 features F1 Score is 0.5045454545454545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = lazy_predict(result_df, features_sortedx[9:], norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM86cUWDSMG7",
        "outputId": "22691363-0823-4909-be27-a2181044c985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 10.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "KTVsCz5TS198",
        "outputId": "ff8d71c3-3646-418e-95db-77a2e7f34269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "NearestCentroid                    0.53               0.53     0.53      0.53   \n",
              "AdaBoostClassifier                 0.53               0.51     0.51      0.46   \n",
              "XGBClassifier                      0.53               0.51     0.51      0.46   \n",
              "LGBMClassifier                     0.53               0.51     0.51      0.46   \n",
              "CalibratedClassifierCV             0.53               0.50     0.50      0.37   \n",
              "LogisticRegression                 0.53               0.50     0.50      0.37   \n",
              "BernoulliNB                        0.53               0.50     0.50      0.37   \n",
              "SVC                                0.53               0.50     0.50      0.37   \n",
              "RidgeClassifierCV                  0.53               0.50     0.50      0.37   \n",
              "RidgeClassifier                    0.53               0.50     0.50      0.37   \n",
              "RandomForestClassifier             0.53               0.50     0.50      0.37   \n",
              "QuadraticDiscriminantAnalysis      0.53               0.50     0.50      0.37   \n",
              "Perceptron                         0.53               0.50     0.50      0.37   \n",
              "DummyClassifier                    0.53               0.50     0.50      0.37   \n",
              "LinearSVC                          0.53               0.50     0.50      0.37   \n",
              "BaggingClassifier                  0.53               0.50     0.50      0.37   \n",
              "ExtraTreesClassifier               0.53               0.50     0.50      0.37   \n",
              "GaussianNB                         0.47               0.49     0.49      0.39   \n",
              "ExtraTreeClassifier                0.47               0.46     0.46      0.45   \n",
              "LinearDiscriminantAnalysis         0.47               0.44     0.44      0.34   \n",
              "SGDClassifier                      0.47               0.44     0.44      0.34   \n",
              "PassiveAggressiveClassifier        0.40               0.38     0.38      0.37   \n",
              "KNeighborsClassifier               0.40               0.38     0.38      0.30   \n",
              "LabelSpreading                     0.33               0.32     0.32      0.31   \n",
              "LabelPropagation                   0.33               0.32     0.32      0.31   \n",
              "DecisionTreeClassifier             0.33               0.32     0.32      0.31   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "NearestCentroid                      0.03  \n",
              "AdaBoostClassifier                   0.38  \n",
              "XGBClassifier                        0.14  \n",
              "LGBMClassifier                       0.10  \n",
              "CalibratedClassifierCV               0.16  \n",
              "LogisticRegression                   0.04  \n",
              "BernoulliNB                          0.05  \n",
              "SVC                                  0.06  \n",
              "RidgeClassifierCV                    0.07  \n",
              "RidgeClassifier                      0.03  \n",
              "RandomForestClassifier               0.40  \n",
              "QuadraticDiscriminantAnalysis        0.04  \n",
              "Perceptron                           0.06  \n",
              "DummyClassifier                      0.03  \n",
              "LinearSVC                            0.05  \n",
              "BaggingClassifier                    0.12  \n",
              "ExtraTreesClassifier                 0.39  \n",
              "GaussianNB                           0.04  \n",
              "ExtraTreeClassifier                  0.06  \n",
              "LinearDiscriminantAnalysis           0.03  \n",
              "SGDClassifier                        0.07  \n",
              "PassiveAggressiveClassifier          0.10  \n",
              "KNeighborsClassifier                 0.11  \n",
              "LabelSpreading                       0.03  \n",
              "LabelPropagation                     0.05  \n",
              "DecisionTreeClassifier               0.04  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-359b0eab-2600-44f8-bbaa-db1f98a80481\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelSpreading</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelPropagation</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-359b0eab-2600-44f8-bbaa-db1f98a80481')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-359b0eab-2600-44f8-bbaa-db1f98a80481 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-359b0eab-2600-44f8-bbaa-db1f98a80481');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_three_years(clf, result_df, feature_list, starting_year, norm=False):\n",
        "\n",
        "  if norm == True:\n",
        "    # Select only the numeric columns for scaling\n",
        "    num_cols = result_df.select_dtypes(include=['float', 'int']).drop(columns=['year_x', 'class']).columns\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(result_df[num_cols])\n",
        "    result_df[num_cols] = scaler.transform(result_df[num_cols])\n",
        "\n",
        "  df_train = result_df[(result_df['year_x'] >= starting_year) & (result_df['year_x'] <= 2020)]\n",
        "  df_2021 = result_df[(result_df['year_x'] == 2021)]\n",
        "  df_2022 = result_df[(result_df['year_x'] == 2022)]\n",
        "  df_2023 = result_df[(result_df['year_x'] == 2023)]\n",
        "\n",
        "  X_train = df_train[feature_list]\n",
        "  y_train = df_train[\"class\"]\n",
        "\n",
        "  X_train = StandardScaler().fit_transform(X_train)\n",
        "\n",
        "  X_2021 = df_2021[feature_list]\n",
        "  X_2021 = StandardScaler().fit_transform(X_2021)\n",
        "  y_2021 = df_2021[\"class\"]\n",
        "\n",
        "  X_2022 = df_2022[feature_list]\n",
        "  X_2022 = StandardScaler().fit_transform(X_2022)\n",
        "  y_2022 = df_2022[\"class\"]\n",
        "\n",
        "  X_2023 = df_2023[feature_list]\n",
        "  X_2023 = StandardScaler().fit_transform(X_2023)\n",
        "  y_2023 = df_2023[\"class\"]\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  overall_preds = []\n",
        "  actuals = []\n",
        "\n",
        "\n",
        "  print(\"2021 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2021)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2021.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2021.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2021.loc[df_2021['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"------------------------\")\n",
        "  print(\"2022 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2022)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2022.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2022.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2022.loc[df_2022['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"------------------------\")\n",
        "  print(\"2023 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2023)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2023.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2023.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2023.loc[df_2023['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "\n",
        "  correct = 0\n",
        "  for song in actuals:\n",
        "    if song in overall_preds:\n",
        "      correct += 1\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Got\", correct, \"correct\")\n",
        "  print(\"\")\n",
        "\n",
        "  print(\"Feature Importances: \")\n",
        "  feature_imps = {}\n",
        "  for i in range(len(feature_list)):\n",
        "    feature_imps[feature_list[i]] = clf.feature_importances_[i]\n",
        "  feature_imps = sorted(feature_imps.items(), key=lambda x:x[1],reverse=True)\n",
        "  print(feature_imps)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "Puo2K4EHS47-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "KFJ_lOH-Y-9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "td6xgBQLTC2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_three_years(clf, result_df, features_sortedx[9:], 2004, norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf0j8VetTFH5",
        "outputId": "6d7bab5d-b5dc-4061-8b05-da6a6c9bfde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "Savage\n",
            "The Bigger Picture\n",
            "The Box\n",
            "\n",
            "Actual winner: \n",
            "Savage\n",
            "\n",
            "------------------------\n",
            "2022 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "Jail\n",
            "Best Friend\n",
            "My Life\n",
            "\n",
            "Actual winner: \n",
            "Jail\n",
            "\n",
            "------------------------\n",
            "2023 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "The Heart Part 5\n",
            "Pushin P\n",
            "Wait for U\n",
            "\n",
            "Actual winner: \n",
            "The Heart Part 5\n",
            "\n",
            "Got 3 correct\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_three_years(clf, result_df, features_sortedx[9:], 2004, norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lR50o5Eb3Of",
        "outputId": "d052b79f-c1de-4de1-a118-486c60733f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "Savage\n",
            "The Bigger Picture\n",
            "The Box\n",
            "\n",
            "Actual winner: \n",
            "Savage\n",
            "\n",
            "------------------------\n",
            "2022 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "Jail\n",
            "Best Friend\n",
            "My Life\n",
            "\n",
            "Actual winner: \n",
            "Jail\n",
            "\n",
            "------------------------\n",
            "2023 PREDICTIONS\n",
            "Top 3 predictions:\n",
            "The Heart Part 5\n",
            "Pushin P\n",
            "Wait for U\n",
            "\n",
            "Actual winner: \n",
            "The Heart Part 5\n",
            "\n",
            "Got 3 correct\n",
            "\n",
            "Feature Importances: \n",
            "[('neg_sen', 0.12), ('vocab_diveristy', 0.1), ('num_words', 0.1), ('happy', 0.1), ('key', 0.08), ('fear', 0.08), ('sad', 0.06), ('weeks_in_top_10', 0.06), ('average_position', 0.06), ('profanity', 0.06), ('anger', 0.04), ('surprise', 0.04), ('instrumentalness', 0.02), ('duration_ms', 0.02), ('pos_sen', 0.02), ('tempo', 0.02), ('peak_position', 0.02), ('weeks_on_chart', 0.0), ('weeks_in_top_25', 0.0)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Including search trends"
      ],
      "metadata": {
        "id": "5hUuXzO_ThaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = list(result_df[\"song_x\"])\n",
        "key1 = [i.translate(str.maketrans('', '', string.punctuation)).lower() for i in list1]\n",
        "result_df[\"song_key\"] = key1"
      ],
      "metadata": {
        "id": "6ljxgIwPTPHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the dataframes on the common column 'song_key'\n",
        "combined_df = pd.merge(df_search, result_df, on='song_key', how='inner')"
      ],
      "metadata": {
        "id": "_XMhGDgFUUzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(combined_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFcdXMCzUaUt",
        "outputId": "9a9feab3-1af0-4835-aece-d5b34d3f9ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "DEyqODDLVA3W",
        "outputId": "52f56838-f6fe-4751-dcba-869a427a4f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0            song  year  peak pop  avg pop        song_key  \\\n",
              "0            0   Lose Yourself  2005     69.00    40.85   lose yourself   \n",
              "1            1       Beautiful  2005     10.00     1.18       beautiful   \n",
              "2            2  Excuse Me Miss  2005     16.00     1.36  excuse me miss   \n",
              "3            3      In da Club  2005    100.00    58.51      in da club   \n",
              "4            4         Work It  2005      9.00     1.15         work it   \n",
              "..         ...             ...   ...       ...      ...             ...   \n",
              "83          92            Jail  2023    100.00    87.40            jail   \n",
              "84          93      Bath Salts  2023      1.00     1.00      bath salts   \n",
              "85          94     Best Friend  2023      0.50     0.50     best friend   \n",
              "86          95     Family Ties  2023      2.00     1.02     family ties   \n",
              "87          96         My Life  2023     63.00    56.69         my life   \n",
              "\n",
              "    year_x          song_x                                artist_x  \\\n",
              "0     2004   Lose Yourself                                  Eminem   \n",
              "1     2004       Beautiful                 Snoop Dogg and Pharrell   \n",
              "2     2004  Excuse Me Miss                      Jay-Z and Pharrell   \n",
              "3     2004      In da Club                                 50 Cent   \n",
              "4     2004         Work It                           Missy Elliott   \n",
              "..     ...             ...                                     ...   \n",
              "83    2022            Jail              Kanye West featuring Jay-Z   \n",
              "84    2022      Bath Salts             DMX featuring Jay-Z and Nas   \n",
              "85    2022     Best Friend             Saweetie featuring Doja Cat   \n",
              "86    2022     Family Ties      Baby Keem featuring Kendrick Lamar   \n",
              "87    2022         My Life  J. Cole featuring 21 Savage and Morray   \n",
              "\n",
              "   wasWinner_x  ...  vocab_diveristy  pos_sen  neg_sen  happy  fear  anger  \\\n",
              "0          yes  ...             1.22    -0.02    -0.06   0.15  0.63  -0.22   \n",
              "1           no  ...            -0.42     3.00    -1.14   3.56 -1.38  -0.68   \n",
              "2           no  ...            -0.28    -0.81    -1.05  -0.67 -0.96  -0.33   \n",
              "3           no  ...            -0.46    -0.29    -0.14   1.17 -0.12   0.83   \n",
              "4           no  ...            -0.32    -0.04    -0.94  -0.77  0.80   0.60   \n",
              "..         ...  ...              ...      ...      ...    ...   ...    ...   \n",
              "83         yes  ...            -0.42     3.00    -1.14   3.56 -1.38  -0.68   \n",
              "84          no  ...             3.59     0.20     0.17  -0.21 -0.71   0.02   \n",
              "85          no  ...             0.61     1.05     0.57   1.72  0.21  -0.33   \n",
              "86          no  ...             0.91    -0.29     0.39  -0.31 -0.21   0.36   \n",
              "87          no  ...            -0.02     0.93    -0.92   1.53 -0.54  -0.22   \n",
              "\n",
              "     sad  surprise  profanity  class  \n",
              "0   0.41     -1.02      -0.65      1  \n",
              "1  -0.61     -0.78      -1.80      0  \n",
              "2   2.27     -0.21       0.73      0  \n",
              "3  -0.33     -1.18       0.77      0  \n",
              "4   0.04     -0.54       0.20      0  \n",
              "..   ...       ...        ...    ...  \n",
              "83 -0.61     -0.78      -1.80      1  \n",
              "84 -0.61      1.41       0.65      0  \n",
              "85 -1.82      0.03       0.77      0  \n",
              "86 -1.08      1.25       0.77      0  \n",
              "87  0.04     -0.70      -1.43      0  \n",
              "\n",
              "[88 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d69ed88-b066-4973-ac08-4b28b8eb32c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>peak pop</th>\n",
              "      <th>avg pop</th>\n",
              "      <th>song_key</th>\n",
              "      <th>year_x</th>\n",
              "      <th>song_x</th>\n",
              "      <th>artist_x</th>\n",
              "      <th>wasWinner_x</th>\n",
              "      <th>...</th>\n",
              "      <th>vocab_diveristy</th>\n",
              "      <th>pos_sen</th>\n",
              "      <th>neg_sen</th>\n",
              "      <th>happy</th>\n",
              "      <th>fear</th>\n",
              "      <th>anger</th>\n",
              "      <th>sad</th>\n",
              "      <th>surprise</th>\n",
              "      <th>profanity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Lose Yourself</td>\n",
              "      <td>2005</td>\n",
              "      <td>69.00</td>\n",
              "      <td>40.85</td>\n",
              "      <td>lose yourself</td>\n",
              "      <td>2004</td>\n",
              "      <td>Lose Yourself</td>\n",
              "      <td>Eminem</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.63</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-1.02</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Beautiful</td>\n",
              "      <td>2005</td>\n",
              "      <td>10.00</td>\n",
              "      <td>1.18</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>2004</td>\n",
              "      <td>Beautiful</td>\n",
              "      <td>Snoop Dogg and Pharrell</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.42</td>\n",
              "      <td>3.00</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>3.56</td>\n",
              "      <td>-1.38</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Excuse Me Miss</td>\n",
              "      <td>2005</td>\n",
              "      <td>16.00</td>\n",
              "      <td>1.36</td>\n",
              "      <td>excuse me miss</td>\n",
              "      <td>2004</td>\n",
              "      <td>Excuse Me Miss</td>\n",
              "      <td>Jay-Z and Pharrell</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>-0.81</td>\n",
              "      <td>-1.05</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-0.96</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>2.27</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>In da Club</td>\n",
              "      <td>2005</td>\n",
              "      <td>100.00</td>\n",
              "      <td>58.51</td>\n",
              "      <td>in da club</td>\n",
              "      <td>2004</td>\n",
              "      <td>In da Club</td>\n",
              "      <td>50 Cent</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>1.17</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.83</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Work It</td>\n",
              "      <td>2005</td>\n",
              "      <td>9.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>work it</td>\n",
              "      <td>2004</td>\n",
              "      <td>Work It</td>\n",
              "      <td>Missy Elliott</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.94</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>92</td>\n",
              "      <td>Jail</td>\n",
              "      <td>2023</td>\n",
              "      <td>100.00</td>\n",
              "      <td>87.40</td>\n",
              "      <td>jail</td>\n",
              "      <td>2022</td>\n",
              "      <td>Jail</td>\n",
              "      <td>Kanye West featuring Jay-Z</td>\n",
              "      <td>yes</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.42</td>\n",
              "      <td>3.00</td>\n",
              "      <td>-1.14</td>\n",
              "      <td>3.56</td>\n",
              "      <td>-1.38</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.78</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>93</td>\n",
              "      <td>Bath Salts</td>\n",
              "      <td>2023</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>bath salts</td>\n",
              "      <td>2022</td>\n",
              "      <td>Bath Salts</td>\n",
              "      <td>DMX featuring Jay-Z and Nas</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>3.59</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>94</td>\n",
              "      <td>Best Friend</td>\n",
              "      <td>2023</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>best friend</td>\n",
              "      <td>2022</td>\n",
              "      <td>Best Friend</td>\n",
              "      <td>Saweetie featuring Doja Cat</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.05</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.72</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-1.82</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>95</td>\n",
              "      <td>Family Ties</td>\n",
              "      <td>2023</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.02</td>\n",
              "      <td>family ties</td>\n",
              "      <td>2022</td>\n",
              "      <td>Family Ties</td>\n",
              "      <td>Baby Keem featuring Kendrick Lamar</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>0.91</td>\n",
              "      <td>-0.29</td>\n",
              "      <td>0.39</td>\n",
              "      <td>-0.31</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.36</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>96</td>\n",
              "      <td>My Life</td>\n",
              "      <td>2023</td>\n",
              "      <td>63.00</td>\n",
              "      <td>56.69</td>\n",
              "      <td>my life</td>\n",
              "      <td>2022</td>\n",
              "      <td>My Life</td>\n",
              "      <td>J. Cole featuring 21 Savage and Morray</td>\n",
              "      <td>no</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.93</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>1.53</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-1.43</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d69ed88-b066-4973-ac08-4b28b8eb32c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d69ed88-b066-4973-ac08-4b28b8eb32c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d69ed88-b066-4973-ac08-4b28b8eb32c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = ['peak pop', 'avg pop', 'song_key', 'weeks_in_top_25', 'weeks_in_top_10',\n",
        "       'weeks_on_chart', 'peak_position', 'average_position', 'danceability',\n",
        "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
        "       'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms',\n",
        "       'time_signature', 'num_words', 'vocab_diveristy', 'pos_sen', 'neg_sen',\n",
        "       'happy', 'fear', 'anger', 'sad', 'surprise', 'profanity', 'class']"
      ],
      "metadata": {
        "id": "fq4jw-GIUbip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_variance = {}\n",
        "for feature in feature_list:\n",
        "    values = np.array(result_df[feature])\n",
        "    x_norm = (values-np.min(values))/(np.max(values)-np.min(values))\n",
        "    var = np.var(x_norm)\n",
        "    #print(\"Variance for\", feature, \"=\", var)\n",
        "    feature_variance[feature] = var"
      ],
      "metadata": {
        "id": "tV_xeW4iUd3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_variance = sorted(feature_variance.items(), key=lambda x:x[1])\n",
        "features_sorted = []\n",
        "for var in sorted_variance:\n",
        "  print(var)\n",
        "  features_sorted.append(var[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5gxIuGRUfgu",
        "outputId": "0c9fdf47-98ce-4877-a31a-b45f0bdf37de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('loudness', 0.00846953856975993)\n",
            "('time_signature', 0.00939414049586777)\n",
            "('energy', 0.009796407988818858)\n",
            "('mode', 0.009811370830289745)\n",
            "('valence', 0.009821089490148814)\n",
            "('danceability', 0.009842259666214836)\n",
            "('speechiness', 0.009869134327241496)\n",
            "('liveness', 0.009870246852791455)\n",
            "('acousticness', 0.00987634020683224)\n",
            "('instrumentalness', 0.009897865162751573)\n",
            "('key', 0.010189919649379105)\n",
            "('duration_ms', 0.014009249942909873)\n",
            "('anger', 0.017585893491124258)\n",
            "('surprise', 0.02062677122769065)\n",
            "('vocab_diveristy', 0.026280208706098)\n",
            "('num_words', 0.029771441640162783)\n",
            "('neg_sen', 0.03453313042981252)\n",
            "('happy', 0.04206518333926664)\n",
            "('fear', 0.04695854545454546)\n",
            "('sad', 0.048330653894210734)\n",
            "('pos_sen', 0.04960195971634842)\n",
            "('tempo', 0.05404197015842072)\n",
            "('weeks_on_chart', 0.05800347222222222)\n",
            "('weeks_in_top_10', 0.08155310650887575)\n",
            "('average_position', 0.08954117705318801)\n",
            "('weeks_in_top_25', 0.09304794921874997)\n",
            "('peak_position', 0.10486790685104273)\n",
            "('profanity', 0.11381560085208607)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  models = lazy_predict(combined_df, features_sorted[i:], norm=True)\n",
        "  print(\"Removing\", i, \"features\", \"F1 Score is\", models.iloc[0][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8FmtBmUhiq",
        "outputId": "bcd03ff6-c9c8-4b76-9515-665f9171ed95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:03<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 0 features F1 Score is 0.7142857142857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 21.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 1 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 2 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 30.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 3 features F1 Score is 0.7142857142857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 4 features F1 Score is 0.6928571428571428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 5 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 6 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 7 features F1 Score is 0.7794486215538846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 8 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 9 features F1 Score is 0.7551020408163265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "8FK41kHmUkq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_three_years(clf, combined_df, features_sorted[0:], 2005, norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "9HRYTZXkU9m7",
        "outputId": "c9b65e04-781d-46e3-cb8e-6e351decd1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c4f96f38dd77>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_three_years\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-57c0527554c8>\u001b[0m in \u001b[0;36mevaluate_three_years\u001b[0;34m(clf, result_df, feature_list, starting_year, norm)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mX_2023\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2023\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mX_2023\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2023\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0my_2023\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_2023\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 28)) while a minimum of 1 is required by StandardScaler."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE"
      ],
      "metadata": {
        "id": "WfSw0wBlXDcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ74foB1XFwu",
        "outputId": "b3944b37-7ad9-48eb-f91b-0e48e18489b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "0qRyUMFfXJ4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lazy_predict_smote(result_df, feature_list, norm=False, print=False):\n",
        "  X = result_df[feature_list]\n",
        "  y = result_df[\"class\"]\n",
        "\n",
        "  # transform the dataset\n",
        "  over = SMOTE(sampling_strategy=0.4)\n",
        "  steps = [('over', over)]\n",
        "  pipeline = Pipeline(steps=steps)\n",
        "  X, y = pipeline.fit_resample(X, y)\n",
        "\n",
        "  if norm == True:\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X)\n",
        "    X = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.15,random_state=42)\n",
        "\n",
        "  clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "  models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "  if print == True:\n",
        "    print(models)\n",
        "  return models"
      ],
      "metadata": {
        "id": "6ujHtvw6XMC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "  models = lazy_predict_smote(combined_df, features_sorted[i:], norm=True)\n",
        "  print(\"Removing\", i, \"features\", \"F1 Score is\", models.iloc[0][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZWuroClXPIA",
        "outputId": "df991a54-0581-41a9-f96a-9a2c6a952a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 0 features F1 Score is 0.856060606060606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 1 features F1 Score is 0.9312169312169313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 2 features F1 Score is 0.856060606060606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 3 features F1 Score is 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 4 features F1 Score is 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 5 features F1 Score is 0.8054298642533937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 6 features F1 Score is 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 7 features F1 Score is 0.856060606060606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 8 features F1 Score is 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 9 features F1 Score is 0.7936507936507937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 27.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 10 features F1 Score is 0.856060606060606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 11 features F1 Score is 0.8703703703703703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 12 features F1 Score is 0.7407407407407407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 29.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 13 features F1 Score is 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 28.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 14 features F1 Score is 0.8666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = lazy_predict_smote(combined_df, features_sorted[2:], norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IflkeNjrXRuW",
        "outputId": "781767af-516d-45d4-a2b5-5b6807a30284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:03<00:00,  7.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "uAg0UUknXkJ5",
        "outputId": "f63c5463-eb52-4d41-8837-c45782b7b1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "ExtraTreeClassifier                0.87               0.90     0.90      0.87   \n",
              "ExtraTreesClassifier               0.93               0.90     0.90      0.93   \n",
              "LabelPropagation                   0.87               0.90     0.90      0.87   \n",
              "LabelSpreading                     0.87               0.90     0.90      0.87   \n",
              "AdaBoostClassifier                 0.80               0.80     0.80      0.80   \n",
              "RandomForestClassifier             0.87               0.80     0.80      0.86   \n",
              "BaggingClassifier                  0.87               0.80     0.80      0.86   \n",
              "LinearDiscriminantAnalysis         0.73               0.75     0.75      0.74   \n",
              "XGBClassifier                      0.80               0.70     0.70      0.77   \n",
              "NuSVC                              0.80               0.70     0.70      0.77   \n",
              "RidgeClassifier                    0.73               0.65     0.65      0.71   \n",
              "Perceptron                         0.73               0.65     0.65      0.71   \n",
              "LinearSVC                          0.73               0.65     0.65      0.71   \n",
              "KNeighborsClassifier               0.73               0.65     0.65      0.71   \n",
              "PassiveAggressiveClassifier        0.53               0.60     0.60      0.53   \n",
              "LogisticRegression                 0.73               0.60     0.60      0.67   \n",
              "QuadraticDiscriminantAnalysis      0.73               0.60     0.60      0.67   \n",
              "LGBMClassifier                     0.73               0.60     0.60      0.67   \n",
              "DecisionTreeClassifier             0.53               0.55     0.55      0.55   \n",
              "BernoulliNB                        0.67               0.55     0.55      0.62   \n",
              "GaussianNB                         0.33               0.50     0.50      0.17   \n",
              "DummyClassifier                    0.67               0.50     0.50      0.53   \n",
              "CalibratedClassifierCV             0.67               0.50     0.50      0.53   \n",
              "RidgeClassifierCV                  0.67               0.50     0.50      0.53   \n",
              "SGDClassifier                      0.53               0.50     0.50      0.54   \n",
              "SVC                                0.67               0.50     0.50      0.53   \n",
              "NearestCentroid                    0.47               0.45     0.45      0.48   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "ExtraTreeClassifier                  0.06  \n",
              "ExtraTreesClassifier                 0.38  \n",
              "LabelPropagation                     0.08  \n",
              "LabelSpreading                       0.07  \n",
              "AdaBoostClassifier                   0.25  \n",
              "RandomForestClassifier               0.72  \n",
              "BaggingClassifier                    0.12  \n",
              "LinearDiscriminantAnalysis           0.05  \n",
              "XGBClassifier                        0.83  \n",
              "NuSVC                                0.06  \n",
              "RidgeClassifier                      0.06  \n",
              "Perceptron                           0.06  \n",
              "LinearSVC                            0.07  \n",
              "KNeighborsClassifier                 0.10  \n",
              "PassiveAggressiveClassifier          0.09  \n",
              "LogisticRegression                   0.07  \n",
              "QuadraticDiscriminantAnalysis        0.05  \n",
              "LGBMClassifier                       0.14  \n",
              "DecisionTreeClassifier               0.03  \n",
              "BernoulliNB                          0.04  \n",
              "GaussianNB                           0.04  \n",
              "DummyClassifier                      0.05  \n",
              "CalibratedClassifierCV               0.12  \n",
              "RidgeClassifierCV                    0.06  \n",
              "SGDClassifier                        0.07  \n",
              "SVC                                  0.04  \n",
              "NearestCentroid                      0.03  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e799d923-87c7-4f32-b216-f886babbee43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelPropagation</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelSpreading</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e799d923-87c7-4f32-b216-f886babbee43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e799d923-87c7-4f32-b216-f886babbee43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e799d923-87c7-4f32-b216-f886babbee43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_three_years_smote(clf, result_df, feature_list, starting_year, norm=False):\n",
        "\n",
        "  if norm == True:\n",
        "    # Select only the numeric columns for scaling\n",
        "    num_cols = result_df.select_dtypes(include=['float', 'int']).drop(columns=['year_x', 'class']).columns\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(result_df[num_cols])\n",
        "    result_df[num_cols] = scaler.transform(result_df[num_cols])\n",
        "\n",
        "  df_train = result_df[(result_df['year_x'] >= starting_year) & (result_df['year_x'] <= 2020)]\n",
        "  df_2021 = result_df[(result_df['year_x'] == 2021)]\n",
        "  df_2022 = result_df[(result_df['year_x'] == 2022)]\n",
        "  df_2023 = result_df[(result_df['year_x'] == 2023)]\n",
        "\n",
        "  X_train = df_train[feature_list]\n",
        "  y_train = df_train[\"class\"]\n",
        "\n",
        "  # transform the dataset\n",
        "  oversample = RandomOverSampler(sampling_strategy=0.25)\n",
        "  X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "  X_train = StandardScaler().fit_transform(X_train)\n",
        "\n",
        "  X_2021 = df_2021[feature_list]\n",
        "  X_2021 = StandardScaler().fit_transform(X_2021)\n",
        "  y_2021 = df_2021[\"class\"]\n",
        "\n",
        "  X_2022 = df_2022[feature_list]\n",
        "  X_2022 = StandardScaler().fit_transform(X_2022)\n",
        "  y_2022 = df_2022[\"class\"]\n",
        "\n",
        "  X_2023 = df_2023[feature_list]\n",
        "  X_2023 = StandardScaler().fit_transform(X_2023)\n",
        "  y_2023 = df_2023[\"class\"]\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  overall_preds = []\n",
        "  actuals = []\n",
        "\n",
        "\n",
        "  print(\"2021 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2021)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2021.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2021.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2021.loc[df_2021['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"------------------------\")\n",
        "  print(\"2022 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2022)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2022.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2022.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2022.loc[df_2022['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"------------------------\")\n",
        "  print(\"2023 PREDICTIONS\")\n",
        "\n",
        "  proba = clf.predict_proba(X_2023)\n",
        "  proba_win = proba[:, 1]\n",
        "  top_3_ind = np.argpartition(proba_win, -3)[-3:]\n",
        "\n",
        "  print(\"Top 3 predictions:\")\n",
        "  for ind in top_3_ind:\n",
        "      print(df_2023.iloc[ind][\"song_x\"])\n",
        "      overall_preds.append(df_2023.iloc[ind][\"song_x\"])\n",
        "  print(\"\")\n",
        "  print(\"Actual winner: \")\n",
        "  temp = df_2023.loc[df_2023['wasWinner_x'] == 'yes']\n",
        "  print(temp.iloc[0][\"song_x\"])\n",
        "  actuals.append(temp.iloc[0][\"song_x\"])\n",
        "\n",
        "\n",
        "  correct = 0\n",
        "  for song in actuals:\n",
        "    if song in overall_preds:\n",
        "      correct += 1\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Got\", correct, \"correct\")\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "-bn1gNwWXmTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.semi_supervised import LabelPropagation"
      ],
      "metadata": {
        "id": "auKy1lfTX5yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "R37ZPQZ5YDbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_three_years_smote(clf, combined_df, features_sorted[2:], 2005, norm=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "kOJDYRK5YT8I",
        "outputId": "683e9456-ab66-4421-95fb-d2e24d3d7b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-f0c5378fdfbc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_three_years_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-96-37f0d9794cb6>\u001b[0m in \u001b[0;36mevaluate_three_years_smote\u001b[0;34m(clf, result_df, feature_list, starting_year, norm)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# transform the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0moversample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         return OrderedDict(\n\u001b[1;32m    547\u001b[0m             sorted(\n\u001b[0;32m--> 548\u001b[0;31m                 \u001b[0m_sampling_strategy_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m             )\n\u001b[1;32m    550\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36m_sampling_strategy_float\u001b[0;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[1;32m    385\u001b[0m         }\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling_strategy_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0;34m\"The specified ratio required to remove samples \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;34m\"from the minority class while trying to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_x = pd.read_csv(\"rap_combined_not_full.csv\")"
      ],
      "metadata": {
        "id": "_aa7wAFUYZwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_x.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tDVVeIe5osbc",
        "outputId": "9595e07b-9b20-433d-814e-158db407d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Unnamed: 0  year_x  weeks_in_top_25  weeks_in_top_10  \\\n",
              "Unnamed: 0              1.00    1.00            -0.17            -0.13   \n",
              "year_x                  1.00    1.00            -0.17            -0.13   \n",
              "weeks_in_top_25        -0.17   -0.17             1.00             0.87   \n",
              "weeks_in_top_10        -0.13   -0.13             0.87             1.00   \n",
              "weeks_on_chart         -0.22   -0.22             0.87             0.70   \n",
              "peak_position           0.18    0.18            -0.55            -0.46   \n",
              "average_position        0.20    0.20            -0.65            -0.56   \n",
              "danceability            0.07    0.06            -0.09            -0.07   \n",
              "energy                  0.06    0.06            -0.10            -0.08   \n",
              "key                     0.06    0.06            -0.07            -0.03   \n",
              "loudness                0.04    0.04            -0.09            -0.07   \n",
              "mode                    0.07    0.06            -0.10            -0.07   \n",
              "speechiness             0.07    0.06            -0.10            -0.08   \n",
              "acousticness            0.07    0.06            -0.10            -0.08   \n",
              "instrumentalness        0.07    0.06            -0.10            -0.08   \n",
              "liveness                0.07    0.06            -0.10            -0.07   \n",
              "valence                 0.06    0.06            -0.09            -0.07   \n",
              "tempo                   0.01    0.01             0.17             0.06   \n",
              "duration_ms            -0.06   -0.05            -0.11            -0.09   \n",
              "time_signature          0.06    0.05            -0.09            -0.07   \n",
              "num_words              -0.02   -0.01            -0.01            -0.03   \n",
              "vocab_diveristy         0.14    0.14            -0.18            -0.21   \n",
              "pos_sen                 0.07    0.08             0.04             0.06   \n",
              "neg_sen                 0.14    0.15            -0.10            -0.10   \n",
              "happy                   0.10    0.10             0.16             0.10   \n",
              "fear                   -0.03   -0.03             0.01            -0.06   \n",
              "anger                   0.02    0.02            -0.08            -0.02   \n",
              "sad                    -0.11   -0.11            -0.04             0.05   \n",
              "surprise                0.02    0.02            -0.06            -0.07   \n",
              "profanity               0.15    0.15             0.00            -0.01   \n",
              "\n",
              "                  weeks_on_chart  peak_position  average_position  \\\n",
              "Unnamed: 0                 -0.22           0.18              0.20   \n",
              "year_x                     -0.22           0.18              0.20   \n",
              "weeks_in_top_25             0.87          -0.55             -0.65   \n",
              "weeks_in_top_10             0.70          -0.46             -0.56   \n",
              "weeks_on_chart              1.00          -0.61             -0.63   \n",
              "peak_position              -0.61           1.00              0.96   \n",
              "average_position           -0.63           0.96              1.00   \n",
              "danceability               -0.13           0.25              0.23   \n",
              "energy                     -0.14           0.25              0.23   \n",
              "key                        -0.08           0.22              0.21   \n",
              "loudness                   -0.12           0.21              0.20   \n",
              "mode                       -0.14           0.25              0.23   \n",
              "speechiness                -0.14           0.25              0.23   \n",
              "acousticness               -0.14           0.25              0.23   \n",
              "instrumentalness           -0.14           0.25              0.23   \n",
              "liveness                   -0.13           0.25              0.23   \n",
              "valence                    -0.13           0.25              0.23   \n",
              "tempo                       0.18          -0.08             -0.10   \n",
              "duration_ms                -0.12          -0.22             -0.18   \n",
              "time_signature             -0.13           0.25              0.23   \n",
              "num_words                  -0.01          -0.20             -0.21   \n",
              "vocab_diveristy            -0.19           0.17              0.19   \n",
              "pos_sen                    -0.06          -0.10             -0.11   \n",
              "neg_sen                    -0.06          -0.02              0.02   \n",
              "happy                       0.14          -0.02             -0.02   \n",
              "fear                        0.09          -0.07             -0.06   \n",
              "anger                      -0.09           0.06              0.07   \n",
              "sad                        -0.03          -0.12             -0.13   \n",
              "surprise                   -0.13           0.15              0.14   \n",
              "profanity                   0.02          -0.07             -0.07   \n",
              "\n",
              "                  danceability  energy   key  ...  num_words  vocab_diveristy  \\\n",
              "Unnamed: 0                0.07    0.06  0.06  ...      -0.02             0.14   \n",
              "year_x                    0.06    0.06  0.06  ...      -0.01             0.14   \n",
              "weeks_in_top_25          -0.09   -0.10 -0.07  ...      -0.01            -0.18   \n",
              "weeks_in_top_10          -0.07   -0.08 -0.03  ...      -0.03            -0.21   \n",
              "weeks_on_chart           -0.13   -0.14 -0.08  ...      -0.01            -0.19   \n",
              "peak_position             0.25    0.25  0.22  ...      -0.20             0.17   \n",
              "average_position          0.23    0.23  0.21  ...      -0.21             0.19   \n",
              "danceability              1.00    1.00  0.94  ...      -0.06            -0.06   \n",
              "energy                    1.00    1.00  0.94  ...      -0.06            -0.06   \n",
              "key                       0.94    0.94  1.00  ...      -0.07            -0.05   \n",
              "loudness                  0.98    0.98  0.92  ...      -0.05            -0.04   \n",
              "mode                      1.00    1.00  0.93  ...      -0.06            -0.06   \n",
              "speechiness               1.00    1.00  0.94  ...      -0.06            -0.05   \n",
              "acousticness              1.00    1.00  0.94  ...      -0.06            -0.05   \n",
              "instrumentalness          1.00    1.00  0.94  ...      -0.06            -0.06   \n",
              "liveness                  1.00    1.00  0.94  ...      -0.06            -0.05   \n",
              "valence                   1.00    1.00  0.94  ...      -0.06            -0.06   \n",
              "tempo                    -0.02   -0.02 -0.02  ...       0.05            -0.16   \n",
              "duration_ms              -0.41   -0.41 -0.39  ...       0.44             0.02   \n",
              "time_signature            1.00    1.00  0.94  ...      -0.07            -0.06   \n",
              "num_words                -0.06   -0.06 -0.07  ...       1.00            -0.20   \n",
              "vocab_diveristy          -0.06   -0.06 -0.05  ...      -0.20             1.00   \n",
              "pos_sen                   0.06    0.06  0.06  ...      -0.01            -0.07   \n",
              "neg_sen                  -0.15   -0.15 -0.14  ...       0.23             0.08   \n",
              "happy                    -0.06   -0.06 -0.03  ...      -0.26             0.01   \n",
              "fear                      0.23    0.23  0.18  ...       0.28            -0.02   \n",
              "anger                    -0.09   -0.09 -0.04  ...      -0.03            -0.05   \n",
              "sad                      -0.13   -0.13 -0.09  ...       0.00            -0.01   \n",
              "surprise                 -0.01   -0.00 -0.04  ...      -0.03             0.07   \n",
              "profanity                -0.05   -0.05 -0.02  ...       0.38             0.35   \n",
              "\n",
              "                  pos_sen  neg_sen  happy  fear  anger   sad  surprise  \\\n",
              "Unnamed: 0           0.07     0.14   0.10 -0.03   0.02 -0.11      0.02   \n",
              "year_x               0.08     0.15   0.10 -0.03   0.02 -0.11      0.02   \n",
              "weeks_in_top_25      0.04    -0.10   0.16  0.01  -0.08 -0.04     -0.06   \n",
              "weeks_in_top_10      0.06    -0.10   0.10 -0.06  -0.02  0.05     -0.07   \n",
              "weeks_on_chart      -0.06    -0.06   0.14  0.09  -0.09 -0.03     -0.13   \n",
              "peak_position       -0.10    -0.02  -0.02 -0.07   0.06 -0.12      0.15   \n",
              "average_position    -0.11     0.02  -0.02 -0.06   0.07 -0.13      0.14   \n",
              "danceability         0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.01   \n",
              "energy               0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.00   \n",
              "key                  0.06    -0.14  -0.03  0.18  -0.04 -0.09     -0.04   \n",
              "loudness             0.02    -0.18  -0.10  0.24  -0.08 -0.14      0.02   \n",
              "mode                 0.06    -0.15  -0.06  0.23  -0.10 -0.12      0.00   \n",
              "speechiness          0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.01   \n",
              "acousticness         0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.00   \n",
              "instrumentalness     0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.00   \n",
              "liveness             0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.00   \n",
              "valence              0.06    -0.15  -0.06  0.23  -0.09 -0.13     -0.01   \n",
              "tempo               -0.13     0.05   0.16  0.05  -0.06 -0.06     -0.10   \n",
              "duration_ms          0.09    -0.02  -0.02 -0.10   0.03  0.06      0.05   \n",
              "time_signature       0.05    -0.15  -0.06  0.23  -0.09 -0.12     -0.01   \n",
              "num_words           -0.01     0.23  -0.26  0.28  -0.03  0.00     -0.03   \n",
              "vocab_diveristy     -0.07     0.08   0.01 -0.02  -0.05 -0.01      0.07   \n",
              "pos_sen              1.00    -0.13   0.41 -0.02  -0.13 -0.12     -0.16   \n",
              "neg_sen             -0.13     1.00  -0.08  0.11   0.25 -0.13     -0.10   \n",
              "happy                0.41    -0.08   1.00 -0.30  -0.25 -0.24     -0.21   \n",
              "fear                -0.02     0.11  -0.30  1.00  -0.20 -0.26     -0.34   \n",
              "anger               -0.13     0.25  -0.25 -0.20   1.00 -0.06     -0.22   \n",
              "sad                 -0.12    -0.13  -0.24 -0.26  -0.06  1.00     -0.36   \n",
              "surprise            -0.16    -0.10  -0.21 -0.34  -0.22 -0.36      1.00   \n",
              "profanity           -0.24     0.42  -0.16  0.30  -0.03 -0.00     -0.12   \n",
              "\n",
              "                  profanity  \n",
              "Unnamed: 0             0.15  \n",
              "year_x                 0.15  \n",
              "weeks_in_top_25        0.00  \n",
              "weeks_in_top_10       -0.01  \n",
              "weeks_on_chart         0.02  \n",
              "peak_position         -0.07  \n",
              "average_position      -0.07  \n",
              "danceability          -0.05  \n",
              "energy                -0.05  \n",
              "key                   -0.02  \n",
              "loudness              -0.03  \n",
              "mode                  -0.06  \n",
              "speechiness           -0.05  \n",
              "acousticness          -0.06  \n",
              "instrumentalness      -0.05  \n",
              "liveness              -0.05  \n",
              "valence               -0.06  \n",
              "tempo                  0.03  \n",
              "duration_ms            0.05  \n",
              "time_signature        -0.06  \n",
              "num_words              0.38  \n",
              "vocab_diveristy        0.35  \n",
              "pos_sen               -0.24  \n",
              "neg_sen                0.42  \n",
              "happy                 -0.16  \n",
              "fear                   0.30  \n",
              "anger                 -0.03  \n",
              "sad                   -0.00  \n",
              "surprise              -0.12  \n",
              "profanity              1.00  \n",
              "\n",
              "[30 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d1e42f1-6696-4455-9a14-7bd4e8d7673a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>year_x</th>\n",
              "      <th>weeks_in_top_25</th>\n",
              "      <th>weeks_in_top_10</th>\n",
              "      <th>weeks_on_chart</th>\n",
              "      <th>peak_position</th>\n",
              "      <th>average_position</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>...</th>\n",
              "      <th>num_words</th>\n",
              "      <th>vocab_diveristy</th>\n",
              "      <th>pos_sen</th>\n",
              "      <th>neg_sen</th>\n",
              "      <th>happy</th>\n",
              "      <th>fear</th>\n",
              "      <th>anger</th>\n",
              "      <th>sad</th>\n",
              "      <th>surprise</th>\n",
              "      <th>profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year_x</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_in_top_25</th>\n",
              "      <td>-0.17</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_in_top_10</th>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weeks_on_chart</th>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>peak_position</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.22</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_position</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.21</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>danceability</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>key</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loudness</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.92</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mode</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.93</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>speechiness</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acousticness</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instrumentalness</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>liveness</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tempo</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration_ms</th>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>...</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_signature</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_words</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.28</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vocab_diveristy</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos_sen</th>\n",
              "      <td>0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neg_sen</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.18</td>\n",
              "      <td>...</td>\n",
              "      <td>0.28</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.34</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profanity</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.35</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.42</td>\n",
              "      <td>-0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d1e42f1-6696-4455-9a14-7bd4e8d7673a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d1e42f1-6696-4455-9a14-7bd4e8d7673a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d1e42f1-6696-4455-9a14-7bd4e8d7673a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QnvCQ4Zot2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}